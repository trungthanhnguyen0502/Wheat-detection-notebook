{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from random import choice, choices, shuffle\n",
    "import re\n",
    "from ipywidgets import IntProgress\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensor, ToTensorV2\n",
    "\n",
    "\n",
    "BOX_COLOR = (0, 0, 255)\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "TRAIN_IMG_DIR = \"./wheat-dataset/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show 1 ảnh\n",
    "def plot_img(img, size=(7,7), is_rgb=False):\n",
    "    plt.figure(figsize=size)\n",
    "    if is_rgb:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img[:,:,::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#show nhiều ảnh\n",
    "def plot_imgs(imgs, cols=5, size=7, is_rgb=False):\n",
    "    rows = len(imgs)//cols + 1\n",
    "    fig = plt.figure(figsize=(cols*size, rows*size))\n",
    "    for i, img in enumerate(imgs):\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        if is_rgb:\n",
    "            plt.imshow(img)\n",
    "        else:\n",
    "            plt.imshow(img[:,:,::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# vẽ bounding box lên ảnh\n",
    "def visualize_bbox(img, boxes, thickness=3, color=BOX_COLOR):\n",
    "    img_copy = img.copy()\n",
    "    for box in boxes:\n",
    "        img_copy = cv2.rectangle(\n",
    "            img_copy,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, thickness)\n",
    "    return img_copy\n",
    "\n",
    "\n",
    "# vẽ bounding box lên ảnh\n",
    "def load_img(img_id, folder=TRAIN_IMG_DIR):\n",
    "    img_fn = f\"{folder}/{img_id}.jpg\"\n",
    "    img = cv2.imread(img_fn).astype(np.float32)\n",
    "    img /= 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chuyển đổi cặp [imgs, targets] sang dạng tensor theo device cpu/gpu\n",
    "def data_to_device(images, targets, device=torch.device(\"cuda\")):\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "def expand_bbox(x):\n",
    "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
    "    if len(r) == 0:\n",
    "        r = [-1, -1, -1, -1]\n",
    "    return r\n",
    "\n",
    "\n",
    "# đọc data từ file csv\n",
    "# output là 1 list chứa thông tin về các ảnh\n",
    "# mỗi phần tử bao gồm 1 image_id và 1 list các bounding box\n",
    "def read_data_in_csv(csv_path=\"./wheat-dataset/train.csv\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['x'], df['y'],  df['w'], df['h'] = -1, -1, -1, -1\n",
    "    df[['x', 'y', 'w', 'h']] = np.stack(df['bbox'].apply(lambda x: expand_bbox(x)))\n",
    "    df.drop(columns=['bbox'], inplace=True)\n",
    "    df['x'] = df['x'].astype(np.float)\n",
    "    df['y'] = df['y'].astype(np.float)\n",
    "    df['w'] = df['w'].astype(np.float)\n",
    "    df['h'] = df['h'].astype(np.float)\n",
    "    objs = []\n",
    "    img_ids = set(df[\"image_id\"])\n",
    "    \n",
    "    for img_id in tqdm(img_ids):\n",
    "        records = df[df[\"image_id\"] == img_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        area = boxes[:,2]*boxes[:,3]\n",
    "        boxes[:,2] = boxes[:,0] + boxes[:,2]\n",
    "        boxes[:,3] = boxes[:,1] + boxes[:,3]\n",
    "\n",
    "        obj = {\n",
    "            \"img_id\": img_id,\n",
    "            \"boxes\": boxes,\n",
    "            \"area\":area\n",
    "        }\n",
    "        objs.append(obj)\n",
    "    return objs\n",
    "\n",
    "\n",
    "class WheatDataset(Dataset):\n",
    "    def __init__(self, data, img_dir ,transform=None):\n",
    "        self.data = data\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.data[idx]\n",
    "        bboxes = img_data[\"boxes\"]\n",
    "        box_nb = len(bboxes)\n",
    "        labels = torch.ones((box_nb,), dtype=torch.int64)\n",
    "        iscrowd = torch.zeros((box_nb,), dtype=torch.int64)\n",
    "        img = load_img(img_data[\"img_id\"], self.img_dir)\n",
    "        area = img_data[\"area\"]\n",
    "        if self.transform is not None:\n",
    "            sample = {\n",
    "                \"image\":img,\n",
    "                \"bboxes\": bboxes,\n",
    "                \"labels\": labels,\n",
    "                \"area\": area\n",
    "            }\n",
    "            sample = self.transform(**sample)\n",
    "            img = sample['image']\n",
    "            area = sample[\"area\"]\n",
    "            bboxes = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = bboxes.type(torch.float32)\n",
    "        target['labels'] = labels\n",
    "        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target['iscrowd'] = iscrowd\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data form csv file\n",
    "data = read_data_in_csv()\n",
    "shuffle(data)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# tạo transform cho dataset - các biến đổi để augmentation data\n",
    "train_transform = A.Compose(\n",
    "    [A.Flip(0.5), ToTensorV2(p=1.0)],\n",
    "    bbox_params={\n",
    "        \"format\":\"pascal_voc\",\n",
    "        'label_fields': ['labels']\n",
    "})\n",
    "\n",
    "# khởi tạo Dataset và Dataloader\n",
    "train_dataset = WheatDataset(data, img_dir=TRAIN_IMG_DIR, transform=train_transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Khởi tạo model\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "iters = 1\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, progress=False)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0, weight_decay=0.0005)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# tiến hành train model\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = data_to_device(images, targets)\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        iters += 1\n",
    "\n",
    "        # show loss per 30 iteration\n",
    "        if iters%30 == 0:\n",
    "            print(f\"Iteration #{iters} loss: {loss_value}\")\n",
    "            \n",
    "        # để đơn giản, ta save model mỗi 90 iteration\n",
    "        if iters%90 == 0:\n",
    "            model_path = f\"./saved_model/model_{iters}_{round(loss_value, 2)}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
