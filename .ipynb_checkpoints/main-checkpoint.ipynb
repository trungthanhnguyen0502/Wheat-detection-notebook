{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from random import choice, choices, shuffle\n",
    "import re\n",
    "from ipywidgets import IntProgress\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensor, ToTensorV2\n",
    "\n",
    "\n",
    "BOX_COLOR = (0, 0, 255)\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "TRAIN_IMG_DIR = \"./wheat-dataset/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show 1 ảnh\n",
    "def plot_img(img, size=(7,7), is_rgb=False):\n",
    "    plt.figure(figsize=size)\n",
    "    if is_rgb:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img[:,:,::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#show nhiều ảnh\n",
    "def plot_imgs(imgs, cols=5, size=7, is_rgb=False):\n",
    "    rows = len(imgs)//cols + 1\n",
    "    fig = plt.figure(figsize=(cols*size, rows*size))\n",
    "    for i, img in enumerate(imgs):\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        if is_rgb:\n",
    "            plt.imshow(img)\n",
    "        else:\n",
    "            plt.imshow(img[:,:,::-1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# vẽ bounding box lên ảnh\n",
    "def visualize_bbox(img, boxes, thickness=3, color=BOX_COLOR):\n",
    "    img_copy = img.copy()\n",
    "    for box in boxes:\n",
    "        img_copy = cv2.rectangle(\n",
    "            img_copy,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, thickness)\n",
    "    return img_copy\n",
    "\n",
    "\n",
    "# vẽ bounding box lên ảnh\n",
    "def load_img(img_id, folder=TRAIN_IMG_DIR):\n",
    "    img_fn = f\"{folder}/{img_id}.jpg\"\n",
    "    img = cv2.imread(img_fn).astype(np.float32)\n",
    "    img /= 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chuyển đổi cặp [imgs, targets] sang dạng tensor theo device cpu/gpu\n",
    "def data_to_device(images, targets, device=torch.device(\"cuda\")):\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    return images, targets\n",
    "\n",
    "def expand_bbox(x):\n",
    "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
    "    if len(r) == 0:\n",
    "        r = [-1, -1, -1, -1]\n",
    "    return r\n",
    "\n",
    "def read_data_in_csv(csv_path=\"./wheat-dataset/train.csv\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['x'], df['y'],  df['w'], df['h'] = -1, -1, -1, -1\n",
    "    df[['x', 'y', 'w', 'h']] = np.stack(df['bbox'].apply(lambda x: expand_bbox(x)))\n",
    "    df.drop(columns=['bbox'], inplace=True)\n",
    "    df['x'] = df['x'].astype(np.float)\n",
    "    df['y'] = df['y'].astype(np.float)\n",
    "    df['w'] = df['w'].astype(np.float)\n",
    "    df['h'] = df['h'].astype(np.float)\n",
    "    objs = []\n",
    "    img_ids = set(df[\"image_id\"])\n",
    "    \n",
    "    for img_id in tqdm(img_ids):\n",
    "        records = df[df[\"image_id\"] == img_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        area = boxes[:,2]*boxes[:,3]\n",
    "        boxes[:,2] = boxes[:,0] + boxes[:,2]\n",
    "        boxes[:,3] = boxes[:,1] + boxes[:,3]\n",
    "\n",
    "        obj = {\n",
    "            \"img_id\": img_id,\n",
    "            \"boxes\": boxes,\n",
    "            \"area\":area\n",
    "        }\n",
    "        objs.append(obj)\n",
    "    return objs\n",
    "\n",
    "\n",
    "class WheatDataset(Dataset):\n",
    "    def __init__(self, data, img_dir ,transform=None):\n",
    "        self.data = data\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.data[idx]\n",
    "        bboxes = img_data[\"boxes\"]\n",
    "        box_nb = len(bboxes)\n",
    "        labels = torch.ones((box_nb,), dtype=torch.int64)\n",
    "        iscrowd = torch.zeros((box_nb,), dtype=torch.int64)\n",
    "        img = load_img(img_data[\"img_id\"], self.img_dir)\n",
    "        area = img_data[\"area\"]\n",
    "        if self.transform is not None:\n",
    "            sample = {\n",
    "                \"image\":img,\n",
    "                \"bboxes\": bboxes,\n",
    "                \"labels\": labels,\n",
    "                \"area\": area\n",
    "            }\n",
    "            sample = self.transform(**sample)\n",
    "            img = sample['image']\n",
    "            area = sample[\"area\"]\n",
    "            bboxes = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = bboxes.type(torch.float32)\n",
    "        target['labels'] = labels\n",
    "        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target['iscrowd'] = iscrowd\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen.thanh.trungb/.local/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #30 loss: 1.142438530921936\n",
      "Iteration #60 loss: 0.9732915163040161\n",
      "Iteration #90 loss: 0.8440039157867432\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cbf6a889e9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# để đơn giản, ta save model mỗi 90 iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"./saved_model/model_{iters}_{round(loss_value, 2)}.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "#load data form csv file\n",
    "# data = read_data_in_csv()\n",
    "shuffle(data)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# tạo transform cho dataset - các biến đổi để augmentation data\n",
    "train_transform = A.Compose(\n",
    "    [A.Flip(0.5), ToTensorV2(p=1.0)],\n",
    "    bbox_params={\n",
    "        \"format\":\"pascal_voc\",\n",
    "        'label_fields': ['labels']\n",
    "})\n",
    "\n",
    "# khởi tạo Dataset và Dataloader\n",
    "train_dataset = WheatDataset(data, img_dir=TRAIN_IMG_DIR, transform=train_transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Khởi tạo model\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "iters = 1\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, progress=False)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0, weight_decay=0.0005)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# tiến hành train model\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = data_to_device(images, targets)\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        iters += 1\n",
    "\n",
    "        # show loss per 30 iteration\n",
    "        if iters%30 == 0:\n",
    "            print(f\"Iteration #{iters} loss: {loss_value}\")\n",
    "            \n",
    "        # để đơn giản, ta save model mỗi 90 iteration\n",
    "        if iters%90 == 0:\n",
    "            evaluate(model, val_loader, device=device)            \n",
    "            model_path = f\"./saved_model/model_{iters}_{round(loss_value, 2)}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
